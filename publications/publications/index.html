<header class="pub-heading">
	<h4>Manuscripts &amp; Preprints</h4>
</header>
<h5 class="pub-caption">* Works in this section are subject to changes until their official publication</h5>

<ol class="bibliography"><li>
  
    <abbr>[<a href="https://dl.acm.org/conference/chi" target="_blank">CHI</a>]</abbr>
  


<div id="1">
  
    <span class="title">Understanding Emotion Changes in Mobile Experience Sampling</span>
    <span class="author">
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.co.kr/citations?hl=en&amp;user=B9HMz0EAAAAJ" target="_blank">Soowon Kang</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              <em>Cheulyoung Park</em>,
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                Narae Cha,
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://kimauk.github.io/" target="_blank">Auk Kim</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
          <!-- for the last item in the list -->
            
              
                and <a href="https://cs.kaist.ac.kr/people/view?idx=617&amp;kind=faculty&amp;menu=172" target="_blank">Uichin Lee</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In CHI 2022, to appear</em>
    
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  

</div>
</li></ol>

<header class="pub-heading">
	<h4>Refereed Conference &amp; Journal Papers</h4>
</header>

<h3 class="year">2021</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="https://ieeexplore.ieee.org/xpl/conhome/1000269/all-proceedings" target="_blank">EMBC</a>]</abbr>
  


<div id="4">
  
    <span class="title">Arousal-Valence Classification from Peripheral Physiological Signals Using Long Short-Term Memory Networks</span>
    <span class="author">
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                M Sami Zitouni,
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              <em>Cheulyoung Park</em>,
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://cs.kaist.ac.kr/people/view?idx=617&amp;kind=faculty&amp;menu=172" target="_blank">Uichin Lee</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.com/citations?user=OfAkcXkAAAAJ&amp;hl=en" target="_blank">Leontios Hadjileontiadis</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
          <!-- for the last item in the list -->
            
              
                and <a href="https://scholar.google.com/citations?hl=en&amp;user=MpOViugAAAAJ" target="_blank">Ahsan Khandoker</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</em>
    
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/zitouni2021arousal.pdf" target="_blank">pdf</a>]
  
  
    [<a href="https://doi.org/10.1109/EMBC46164.2021.9630252" target="_blank">web</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The automated recognition of human emotions plays an important role in developing machines with emotional intelligence. However, most of the affective computing models are based on images, audio, videos and brain signals. There is a lack of prior studies that focus on utilizing only peripheral physiological signals for emotion recognition, which can ideally be implemented in daily life settings using wearables, e.g., smartwatches. Here, an emotion classification method using peripheral physiological signals, obtained by wearable devices that enable continuous monitoring of emotional states, is presented. A Long Short-Term Memory neural network-based classification model is proposed to accurately predict emotions in real-time into binary levels and quadrants of the arousal-valence space. The peripheral sensored data used here were collected from 20 participants, who engaged in a naturalistic debate. Different annotation schemes were adopted and their impact on the classification performance was explored. Evaluation results demonstrate the capability of our method with a measured accuracy of &gt;93% and &gt;89% for binary levels and quad classes, respectively. This paves the way for enhancing the role of wearable devices in emotional state recognition in everyday life.</p>
  </span>
  

</div>
</li></ol>

<h3 class="year">2020</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="https://www.nature.com/sdata/" target="_blank">Sci. Data</a>]</abbr>
  


<div id="3">
  
    <span class="title">K-EmoCon, a multimodal sensor dataset for continuous emotion recognition in naturalistic conversations</span>
    <span class="author">
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              <em>Cheulyoung Park</em>,
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                Narae Cha,
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.co.kr/citations?hl=en&amp;user=B9HMz0EAAAAJ" target="_blank">Soowon Kang</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://kimauk.github.io/" target="_blank">Auk Kim</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.com/citations?hl=en&amp;user=MpOViugAAAAJ" target="_blank">Ahsan Khandoker</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.com/citations?user=OfAkcXkAAAAJ&amp;hl=en" target="_blank">Leontios Hadjileontiadis</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://aliceoh9.github.io/" target="_blank">Alice Oh</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="http://ibrain.kaist.ac.kr/professor/" target="_blank">Yong Jeong</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
          <!-- for the last item in the list -->
            
              
                and <a href="https://cs.kaist.ac.kr/people/view?idx=617&amp;kind=faculty&amp;menu=172" target="_blank">Uichin Lee</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Nature Scientific Data</em>
    
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/k-emocon.pdf" target="_blank">pdf</a>]
  
  
    [<a href="https://doi.org/10.1038/s41597-020-00630-y" target="_blank">web</a>]
  
  
  
  
  
    [<a href="https://doi.org/10.5281/zenodo.3931963" target="_blank">data</a>]
  
  
    [<a href="https://github.com/Kaist-ICLab/K-EmoCon_SupplementaryCodes" target="_blank">code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recognizing emotions during social interactions has many potential applications with the popularization of low-cost mobile sensors, but a challenge remains with the lack of naturalistic affective interaction data. Most existing emotion datasets do not support studying idiosyncratic emotions arising in the wild as they were collected in constrained environments. Therefore, studying emotions in the context of social interactions requires a novel dataset, and K-EmoCon is such a multimodal dataset with comprehensive annotations of continuous emotions during naturalistic conversations. The dataset contains multimodal measurements, including audiovisual recordings, EEG, and peripheral physiological signals, acquired with off-the-shelf devices from 16 sessions of approximately 10-minute long paired debates on a social issue. Distinct from previous datasets, it includes emotion annotations from all three available perspectives: self, debate partner, and external observers. Raters annotated emotional displays at intervals of every 5 seconds while viewing the debate footage, in terms of arousal-valence and 18 additional categorical emotions. The resulting K-EmoCon is the first publicly available emotion dataset accommodating the multiperspective assessment of emotions during social interactions.</p>
  </span>
  

</div>
</li>
<li>
  
    <abbr>[<a href="https://dl.acm.org/journal/imwut" target="_blank">IMWUT</a>]</abbr>
  


<div id="2">
  
    <span class="title">Hello There! Is Now a Good Time to Talk? Opportune Moments for Proactive Interactions with Smart Speakers</span>
    <span class="author">
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                Narae Cha,
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://kimauk.github.io/" target="_blank">Auk Kim</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              <em>Cheulyoung Park</em>,
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.co.kr/citations?hl=en&amp;user=B9HMz0EAAAAJ" target="_blank">Soowon Kang</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                Mingyu Park,
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://cs.kaist.ac.kr/people/view?idx=616&amp;kind=faculty&amp;menu=160" target="_blank">Jae-Gil Lee</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://scholar.google.com/citations?user=1cgtVW8AAAAJ&amp;hl=en" target="_blank">Sangsu Lee</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
          <!-- for the last item in the list -->
            
              
                and <a href="https://cs.kaist.ac.kr/people/view?idx=617&amp;kind=faculty&amp;menu=172" target="_blank">Uichin Lee</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>
    
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/hellothere.pdf" target="_blank">pdf</a>]
  
  
    [<a href="https://dl.acm.org/doi/10.1145/3411810" target="_blank">web</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Increasing number of researchers and designers are envisioning a wide range of novel proactive conversational services for smart speakers such as context-aware reminders and restocking household items. When initiating conversational interactions proactively, smart speakers need to consider users’ contexts to minimize disruption. In this work, we aim to broaden our understanding of opportune moments for proactive conversational interactions in domestic contexts. Toward this goal, we built a voice-based experience sampling device and conducted a one-week field study with 40 participants living in university dormitories. From 3,572 in-situ user experience reports, we proposed 19 activity categories to investigate contextual factors related to interruptibility. Our data analysis results show that the key determinants for opportune moments are closely related to both personal contextual factors such as busyness, mood, and resource conflicts for dual-tasking, and the other contextual factors associated with the everyday routines at home, including user mobility and social presence. Based on these findings, we discuss the need for designing context-aware proactive conversation management features that dynamically control conversational interactions based on users’ contexts and routines.</p>
  </span>
  

</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="https://dl.acm.org/conference/soups" target="_blank">SOUPS</a>]</abbr>
  


<div id="1">
  
    <span class="title">Share and Share Alike? An Exploration of Secure Behaviors in Romantic Relationships</span>
    <span class="author">
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              <em>Cheulyoung Park</em>,
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://corifaklaris.com/" target="_blank">Cori Faklaris</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="https://www.siyanz.com/" target="_blank">Siyan Zhao</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="http://www.alexsciuto.com/" target="_blank">Alex Sciuto</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
            
              
                <a href="http://www.lauradabbish.com/" target="_blank">Laura Dabbish</a>, 
              
            
          
        
      
      <!-- only one author -->
        
        <!-- else, for items not the last in the list -->
          
          <!-- for the last item in the list -->
            
              
                and <a href="http://www.cs.cmu.edu/~jasonh/" target="_blank">Jason Hong</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Fourteenth Symposium on Usable Privacy and Security (SOUPS)</em>
    
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/soups2018-park.pdf" target="_blank">pdf</a>]
  
  
    [<a href="https://www.usenix.org/conference/soups2018/presentation/park" target="_blank">web</a>]
  
  
  
  
  
  
  
    [<a href="https://www.cylab.cmu.edu/news/2018/09/07-romantic-couples-security.html" target="_blank">press</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Security design choices often fail to take into account users’ social context. Our work is among the first to examine security behavior in romantic relationships. We surveyed 195 people on Amazon Mechanical Turk about their relationship status and account sharing behavior for a cross-section of popular websites and apps (e.g., Netflix, Amazon Prime). We examine differences in account sharing behavior at different stages in a relationship and for people in different age groups and income levels. We also present a taxonomy of sharing motivations and behaviors based on the iterative coding of open-ended responses. Based on this taxonomy, we present design recommendations to support end users in three relationship stages: when they start sharing access with romantic partners; when they are maintaining that sharing; and when they decide to stop. Our findings contribute to the field of usable privacy and security by enhancing our understanding of security and privacy behaviors and needs in intimate social relationships.</p>
  </span>
  

</div>
</li></ol>

